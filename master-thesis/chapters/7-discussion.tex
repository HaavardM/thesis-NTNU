\chapter{Discussion}\label{chap:discussion}

While the methods proposed in this thesis certainly show great promise, there are still many unanswered questions and limitations that need to be discussed. 


\section{A single, global kernel}
Finding a good kernel that works well across a wide range of scenarios turns out to be challenging. For vessels moving along the traffic lanes, simple kernels are preferred as the underlying function is sufficiently smooth. The simple kernels behave a lot more predictably, though perhaps being unrealistically smooth at times. 

More specialized vessels, such as local the ferries in the \acrshort{ais} dataset, requires more complicated kernels to perform well. These vessels move in more chaotic patterns and are harder to predict due to the vessel's behavior when docking for short periods before moving back the same way they came. 

The Direct \acrshort{gp} approach performs well with more complicated kernels and has worked more consistently well with the added flexibility. Overfitting is still a concern, but during the development of the Direct \acrshort{gp} approach, the more flexible kernels were found to yield higher accuracy on most occasions. However,  this thesis has not focused much on kernel design, and no statistical testing has been performed using different kernels. 

The GP-EKF is more sensitive to the kernel choice, and as already discussed in \cref{chap:gp_ekf}, it may lead to instabilities if not chosen carefully. 

\section{Sensitivity to parameters}
The results for the GP-EKF in \cref{chap:stat_testing} heavily depend on the choice of parameters. The basic GP-EKF configuration depends on the initial uncertainty $\boldsymbol{P}_0$, and as it is a pure prediction method, it has a significant impact on the resulting trajectory uncertainty. The \acrshort{sl} update and the \acrshort{pdaf} update also heavily depend on the choice of parameters their respective parameters. A suitable method for selecting good parameters for these methods is still an open research question. 

The problem with both of the update methods is the lack of an appropriate interpretation of the parameters. For the \acrshort{sl} approach, it is unknown what the measurement noise $\boldsymbol{R}$ should be, and it is currently tuned by trial and error. The \acrshort{pdaf} update suffers from a similar problem.

The \acrshort{gp}s also depend on the result of hyperparameter optimization. The \acrshort{ml} approach from \cref{sec:gp_mle} works well on most cases, but there have been several issues with unrealistic hyperparameters. This is especially a problem for GP-EKF, as the best parameters for the motion model $\vec{f}$, does not neccessarily yield the best trajectory prediction and the Jacobian is especially sensitive to short lengthscales. It is important to keep the numerous approximations used by GP-EKF in mind, as it do limit the complexity of the types of motion models.

\section{GP-EKF: The need for incorporating position}
Considering the statistical results for the \acrshort{pdaf} and \acrshort{sl} updates in \cref{fig:stats_gp_ekf_with_or_without_update}, there is little evidence to support that these methods for incorporating position data actually has any benefit. The problem is that both these methods assume the target vessel's predicted position and the historical \acrshort{ais} samples originate from the same underlying trajectory. In practice, the \acrshort{ais} data contains samples from a wide range of different, overlapping trajectories. The \acrshort{pdaf} was, in theory, supposed to reduce this issue with the spread-of-innovation term, however, any effort into finding a good set of parameters has been unsuccessful.  

These update steps were first introduced to solve an issue with the GP-EKF were it would prematurely predict turns, causing large offsets in the predicted trajectory. 


\section{Independent Outputs}

The formulation of vector-valued \acrshort{gp}s in this thesis assumes independent output dimensions. This choice was made to reduce some of the complexity, as \acrshort{gp}s with dependent outputs complicates the derivations, and there is less literature on how to select good kernels when the dimensions are dependent. As a result, the \acrshort{gp}s used in this thesis are unable to express any covariance between the outputs. 

This assumption is a limiting factor for the direct approach as the uncertainty is constrained to specific directions. Without the covariance terms, the model cannot express that the uncertainty is along a given path, such as uncertainty caused by differences in velocity between training samples. A better parametrization would perhaps assume independent lateral and longitudinal components instead, similar to the formulation used by \cite{gp_ais_trajectory}. Such as a decomposition into course and velocity would allow the model more fine-grained control to express uncertainty only in specific directions. Another approach could be to relax the assumption of independent output dimension, though it is unclear how this would be achieved in practice. 

For the dynamical GP-EKF approach, the problem of independent outputs is less problematic. The iterative \acrshort{ekf} procedure allows the model to express covariance in the prediction uncertainty, even if the \acrshort{gp} $\vec{f}$ is limited to independent outputs. However, reparametrization into lateral and longitudinal components could still be beneficial as independent North and East dimensions are unrealistic.  

\section{Shared Kernel}
A similar simplifying assumption is the shared kernel between each output dimension. This choice was also made to reduce complexity and computational efforts, as optimizing the hyperparameters is where this method spends considerable time. Doubling the time spent optimizing was therefore avoided. 

Standardization of the training data already allowed the use of one shared kernel, even if there were differences in scale for the training data, which was considered flexible enough in this thesis.

Whether allowing independent kernels will cause the model to perform better is still an open question. However, it would enable the model to learn separate lengthscale and scale parameters for each output dimension which could be beneficial. 

\section{Clustering}
Clustering of trajectories has not been prioritized in this thesis. Instead, the current implementation of the methods filters the available training data before each prediction, using a set of initial conditions. While this method has worked fine in this thesis, considerable computational improvements can be made from clustering the trajectories offline and select the appropriate cluster when performing predictions. The hyperparameters can then be optimized in advance for each cluster. Combining this work with trajectory clustering methods such as TRACLUS \cite{traclus} may be a good way to tackle some of the computational challenges of the methods proposed in this thesis.

\section{A Global set of hyperparameters}
The implementation used in this thesis performs hyperparameter selection for each prediction and does not reuse the parameters. In practice, it might be better to find a set of hyperparameters that works well in several cases and leave the parameters fixed. Alternatively, the model could use those parameters as initial values and only perform minor tweaks before each prediction. 

\section{Branching Trajectories}
This direct \acrshort{gp} approach works well for unimodal trajectory distribution, where there are only minor variations between the trajectories used for training. However, it can only express unimodal trajectory distributions due to the Gaussian assumption. The method fails as a single Gaussian distribution attempts to describe several modes at once for branching trajectories. The result is a prediction mean somewhere in between the branching trajectories and with large uncertainty. There do exist possible extensions to this method, which could, in theory, allow the model to express multimodal uncertainty. Mixtures of \acrshort{gp}s, often called \textit{Mixture of Experts} (ME), could be used to describe the uncertainty as a Gaussian mixture model. The experts are local \acrshort{gp}s which are assigned points from a \textit{manager} based purely on the input \cite{rasmussen}. The number of experts could even go towards infinity by using a Dirichlet process as the manager \cite{dirichlet_process_gp}. While intriguing, these methods quickly become analytically intractable and require approximate inference methods such as \textit{Markov Chain Monte Carlo} (MCMC) or \acrshort{vi}. 

The dynamical approach used by GP-EKF will, in theory, handle branching trajectories better. The vector-field $\vec{f}$ do indeed express multimodal trajectories as seen in \cref{fig:gp_ekf}, and the trajectory distribution can be found numerically through Sequential Monte-Carlo simulations as seen in \cref{fig:gp_particle}. However, the GP-EKF approach cannot express multimodal uncertainty, as the state is assumed to be a unimodal Gaussian distribution. This forces the GP-EKF to follow one mode, and if unlucky, it might end up trapped between two branching trajectories. The \acrshort{pdaf} was, therefore, implemented to attempt to pull the prediction toward a single mode in the cases where several branching trajectories might influence the prediction model. 



\section{Numerical Gradients}
One concern with the GP-EKF is the need for accurate gradients to use for training. Compared to similar approaches in \cite{vehicle_gp_prediction,pedestrian}, the sampling interval of \acrshort{ais} is in the range of several minutes. The finite difference approach for calculating the gradients should, in theory, be a poor choice for curved trajectories, as it would only be able to capture the average velocity over the large sampling interval and be unable to represent the curvature of the trajectory. Several examples where the numerical gradients caused premature turns were found during testing. The gradients were calculated using points before and after a turn, effectively predicting an unrealistic shortcut.  

Using the reported \acrshort{cog} and \acrshort{sog} was therefore expected to perform better. 

A possible extension to this work could be to attempt a hybrid approach, where the numerical gradients are combined with the \acrshort{cog} and \acrshort{sog} from \acrshort{ais} to get good average performance while still avoiding premature turns. 

\section{Missing state uncertianty}

\section{GP-EKF time dependency}
The time component was initially included to handle trajectories with sharp turns better. For example, if $\vec{f}$ only relied on position, the \acrshort{gp} would have no way of expressing that the speed vector at position $\boldsymbol{x}$ might change over time. The time component was later found to explain some of the variability in the velocity estimates, yielding better uncertainty estimates.

In practice, the \acrshort{ml} approach will, in many cases, yield very large lengthscales\footnote{In fact, the time lengthscale tends to reach a maximum value during optimization} for the time-components of the kernel, effectively disabling the time dependency. The time component is therefore only really used when the dataset contains a lot of time-dependent noise.

\subsection{Numerical issues}



\section{Sparse Variational Gaussian Process}
The \acrshort{svgp} implementation of the direct \acrshort{gp} approach was attempted without success. Even after the training loss started to converge toward an optimum after several hours, the result was unpredictable and unrealistic trajectories. While a few different kernel choices were attempted, the long training time made it inconvenient to work with. Therefore, the efforts were focused elsewhere, as the other methods in this thesis gave better results while also being simpler. 

The \acrshort{svgp} is, however, still included in this thesis to emphasize that there are ways to deal with the high computational complexity of \acrshort{gp}s. The attempt to use \acrshort{svgp} in this thesis tried to do too much at once. While it failed for the problem formulation used in this thesis, the failure is believed to be due to an ill-posed problem rather than an issue with the \acrshort{svgp} itself.