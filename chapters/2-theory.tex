\chapter{Neccessary Theoretical Background}

\section{Useful Results From Probability Theory}
 
\subsection{Joint Probabilities}
The \texttt{joint probability} $p(X, Y)$ is the probability that both $X$ and $Y$ occurs \cite[p.~29]{murphy}.

\begin{equation}
    p(X, Y) = p(X \cap Y) = p(X | Y)p(Y)
\end{equation}

\subsection{Conditional Probabilities}
The \texttt{conditional probability} $p(X | Y)$ is the probability of $X$ occurring, given the known occurence of another event $Y$. This can be interpreted as knowing the value of $Y$ includes some information about $X$. Mathematically it can be expressed as \cite[p.~29]{murphy}
\begin{equation}\label{eq:conditional_probability}
    p(X | Y) = \frac{p(X, Y)}{p(Y)}
\end{equation}

\subsection{Bayes Rule}

A useful extension to equation \eqref{eq:conditional_probability} is to recognize that the joint distribution $p(X, Y)$ can be rewritten as a product of a conditional probability $p(Y | X)$ and $p(X)$. Inserting into equation \eqref{eq:conditional_probability} yields \texttt{Bayes Rule}
\begin{equation}\label{eq:bayes_law}
    p(X | Y) = \frac{p(X, Y)}{p(Y)} = \frac{p(Y | X)p(X)}{p(Y)}.
\end{equation}

As $Y$ is known the denominator $p(Y)$ is simply a normalizing constant. It is sometimes useful to rewrite equation \eqref{eq:bayes_law} as
\begin{equation}\label{eq:bayes_law_proportional}
    p(X | Y) = \frac{p(Y | X) p(X)}{p(Y)} \propto p(Y | X)p(X)
\end{equation} 
which is useful if $p(Y)$ is hard to calculate and the normalized value of $p(X | Y)$ is not needed.

\subsection{Marginal Probability \& The Law of Total Probability}
The marginal probability of an event $X$ is the probability of $X$ occuring irrespective of any other variables.
For notational simplicity we use the integral operator for marginalization of both continuous and discrete random variables, even though the integral is replaced by a sum for discrete random variables. For an event $X$ and any other variables $\bf Y$, the marginal probability of $X$ can be written as
\begin{equation}
    p(X) = \int_{\boldsymbol{Y}} p(X, \boldsymbol{Y}) d\boldsymbol{Y} = \int_{\boldsymbol{Y}} p(X | \boldsymbol{Y}) p(\boldsymbol{Y}) d\boldsymbol{Y}
\end{equation}
The last equation is by the \texttt{Law of total probability} which relates the marginal probabilities to conditional probabilities.

\subsection{Independence \& Conditional Independence}
If the joint probability of two variables $X$ and $Y$ can be expressed as a product of two marginals, then they are marginally independent.
\begin{equation}
    X \perp Y \iff p(X, Y) = p(X | Y)p(Y) = p(Y | X)p(X) = p(X)p(Y)
\end{equation}

Marginal independence is rare, as most variables usually influences each other in some way. However, the variables usually influences each other through other variables and not directly. The variables $X$ and $Y$ is therefore said to be conditionally independent given $Z$ if the conditional joint can be written as a product of conditional marginals \cite[p.~31]{murphy}:
\begin{equation}\label{eq:conditional_independence}
    X \perp Y | Z \iff p(X, Y | Z) = p(X | Z)p(Y | Z)
\end{equation}

\subsection{Interpreting Probability}
The results we have mentioned so far stems from abstract mathematical axioms, and do not tell us how to interpret the resulting probabilities. There are however different interpretations which are commonly accepted. Perhaps the two biggest are the frequentist and bayesian interpretations. 

\begin{description}
    \item[The Frequentist Interpretation:] The frequentists defines an events probability as the limit of it's relative frequency over many trials. In other words, the probabilities are assigned a physical interpretation and remains rather objective. There do however arise issues and paradoxes when we try to assign probabilities to events which are not recurrent, i.e. they only happens a few times. The goal of frequentists is to either reject or accept a hypothesis by evaluting the likelihood of the data $D$ given a model $M$, i.e. $p(D | M)$. 
    \item[The Bayesian Interpretation:] The bayesians interprets probability as a state of knowledge \cite{Jaynes86bayesianmethods:}. Data is used to update prior knowledge about an event, and the probabilities is used to quantify how strongly one believe in each outcome. This interpretation is highly philosophical, but beautifully captures humans intuitive reasoning. The goal of bayesian statistics is to evaluate the likelihood of the model $M$ given the observed data $D$, i.e. $p(M | D)$, usually expressed through Bayes law (\cref{eq:bayes_law}). The bayesian interpretation do however involve a level of subjectivity when choosing priors, making it difficult to form an objective opinion from data. For those interested, see \Cite{Jaynes86bayesianmethods:} for a fascinating read on the history of Bayesian Probability.
\end{description}

While the differences between the frequentist and bayesian interpretations are mostly philosophical, there are a few practial differences. For a frequentist it do not make sense to talk about any probabilities before an experiment has been performed. The prior $p(M)$ and posterior $p(M | D)$ is therefore nonsencical and cannot be computed using a frequentist interpretation.     





\section{Bayesian Statistics}

Using \cref{eq:bayes_law} we can write 
\begin{equation}\label{eq:bayes_learning}
    p(\boldsymbol{\theta}| \mathcal{D}, \boldsymbol{\eta}) = \frac{p(\mathcal{D} | \boldsymbol{\theta}) p(\boldsymbol{\theta} | \boldsymbol{\eta})}{p(\mathcal{D} | \boldsymbol{\eta})} \propto p(\mathcal{D} | \boldsymbol{\theta})p(\boldsymbol{\theta} | \boldsymbol{\eta})
\end{equation}

If $\boldsymbol{\theta}$ is the unknown parameters of a process, $\mathcal{D}$ is collected data or observations, and $\boldsymbol{\eta}$ is all prior knowledge about $\boldsymbol{\theta}$, then equation \eqref{eq:bayes_learning} is a mathematical representation of the process of learning from data \cite{Jaynes86bayesianmethods:}.

\cref{eq:bayes_learning} can be interpreted as
\begin{description}
    \item[The Prior $p(\boldsymbol{\theta} | \boldsymbol{\eta})$:] The prior is knowledge about $\boldsymbol{\theta}$ before observing any data. This can be domain-specific knowledge, results from prior experiments or intuitive reasoning about possible values of $\boldsymbol{\theta}$. 
    \item[The Likelihood $p(\mathcal{D} | \boldsymbol{\theta}, \boldsymbol{\eta})$]: The likelihood of the observations $\mathcal{D}$ is how well the observations fit with the prior beliefs $\boldsymbol{\theta} | \boldsymbol{\eta}$. In other words, how likely is it to observe $\mathcal{D}$ if the current belief $\boldsymbol{\theta} | \boldsymbol{\eta}$ were to be true.
    \item[The Posterior $p(\boldsymbol{\theta} | \mathcal{D}, \boldsymbol{\eta})$]: The posterior distribution is the updated belief about $\boldsymbol{\theta}$. This is knowledge about $\boldsymbol{\theta}$ after observing the data. 
\end{description}

\subsubsection{Selecting a good prior}
As the prior $\boldsymbol{\eta}$ can be hard to determine, the Bayesian approach is to define priors on our prior and create a hierical Bayesian model \cite{murphy}. The relation between the variables can be represented as a graphical model:
\begin{equation*}
    \boldsymbol{\eta} \rightarrow \boldsymbol{\theta} \rightarrow{\mathcal{D}}
\end{equation*}

Another approach is to use a so-called uninformative prior. An uninformative prior is a distribution which do not assign more probability mass to any single outcome, and thereby does not incorporate any prior knowledge. It is like saying it simply does not know what to believe.





\section{Stochastic Modelling}

\section{Probabilistic Graphical Models}

\section{Belief Propagation}

\section{Markov Chains}

